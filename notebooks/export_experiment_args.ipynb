{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ccd84aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3266f0b",
   "metadata": {},
   "source": [
    "### Leingan with ens10 tp stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76e4ad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'gan': 'base',\n",
    "        'seed': 0,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'leingan/ens10_tp/stacked/', \n",
    "                       'run_number': 0                       \n",
    "                      },\n",
    "        'gan_hparams': {'generator': 'leingen',\n",
    "                        'discriminator': 'leindisc',\n",
    "                        'noise_shape' : (1, 16, 16),\n",
    "                        'input_channels' : 10,\n",
    "                        'disc_lr' : 1e-4,\n",
    "                        'gen_lr' : 1e-4,\n",
    "                        'lambda_gp' : 10,\n",
    "                        'gen_freq' : 1, \n",
    "                        'disc_freq':5, \n",
    "                        'disc_spectral_norm' : False,\n",
    "                        'gen_spectral_norm' : False, \n",
    "                        'loss_type' : \"wasserstein\",     \n",
    "                        'val_hparams' : {'val_nens':10}\n",
    "                       },\n",
    "        'train_hparams': {'epochs': 150, \n",
    "                          'gpus': 4, \n",
    "                          'batch_size': 64\n",
    "                         },\n",
    "        'data_hparams': {'train_dataset_path': \"/home/jupyter/data/saved_datasets/traindataset_ensemble_forecast_x10_log_trans_full.pkl\",\n",
    "                        'valid_dataset_path': \"/home/jupyter/data/saved_datasets/validdataset_ensemble_forecast_x10_log_trans_full.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/leingan_ens10_tp_stacked_input.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b03488",
   "metadata": {},
   "source": [
    "### Leingan with ens10 tp random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5537d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'gan': 'base',\n",
    "        'seed': 0,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'leingan/ens10_tp/random/', \n",
    "                       'run_number': 0                       \n",
    "                      },\n",
    "        'gan_hparams': {'generator': 'leingen',\n",
    "                        'discriminator': 'leindisc',\n",
    "                        'noise_shape' : (1, 16, 16),\n",
    "                        'input_channels' : 1,\n",
    "                        'disc_lr' : 1e-4,\n",
    "                        'gen_lr' : 1e-4,\n",
    "                        'lambda_gp' : 10,\n",
    "                        'gen_freq' : 1, \n",
    "                        'disc_freq':5, \n",
    "                        'disc_spectral_norm' : False,\n",
    "                        'gen_spectral_norm' : False, \n",
    "                        'loss_type' : \"wasserstein\",     \n",
    "                        'val_hparams' : {'val_nens':10}\n",
    "                       },\n",
    "        'train_hparams': {'epochs': 200, \n",
    "                          'gpus': 4, \n",
    "                          'batch_size': 64\n",
    "                         },\n",
    "        'data_hparams': {'train_dataset_path': \"/home/jupyter/data/saved_datasets/traindataset_ensemble_forecast_x10_random_log_trans_full.pkl\",\n",
    "                        'valid_dataset_path': \"/home/jupyter/data/saved_datasets/validdataset_ensemble_forecast_x10_random_log_trans_full.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/leingan_ens10_tp_random_input.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7322cd",
   "metadata": {},
   "source": [
    "### Leingan with ens10 temp random lower lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9f699dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'gan': 'base',\n",
    "        'seed': 0,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'leingan/ens10_tp/random/', \n",
    "                       'run_number': 1                       \n",
    "                      },\n",
    "        'gan_hparams': {'generator': 'leingen',\n",
    "                        'discriminator': 'leindisc',\n",
    "                        'noise_shape' : (1, 16, 16),\n",
    "                        'input_channels' : 1,\n",
    "                        'disc_lr' : 5e-5,\n",
    "                        'gen_lr' : 5e-5,\n",
    "                        'lambda_gp' : 10,\n",
    "                        'gen_freq' : 1, \n",
    "                        'disc_freq':5, \n",
    "                        'disc_spectral_norm' : False,\n",
    "                        'gen_spectral_norm' : False, \n",
    "                        'loss_type' : \"wasserstein\",     \n",
    "                        'val_hparams' : {'val_nens':10}\n",
    "                       },\n",
    "        'train_hparams': {'epochs': 200, \n",
    "                          'gpus': 4, \n",
    "                          'batch_size': 64\n",
    "                         },\n",
    "        'data_hparams': {'train_dataset_path': \"/home/jupyter/data/saved_datasets/traindataset_ensemble_forecast_x10_random_log_trans_full.pkl\",\n",
    "                        'valid_dataset_path': \"/home/jupyter/data/saved_datasets/validdataset_ensemble_forecast_x10_random_log_trans_full.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/leingan_ens10_tp_random_input_low_lr.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe10ccf2",
   "metadata": {},
   "source": [
    "### Leingan with ens10 tp random - gen loss: ens_mean_L1_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da3f60c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "args = {'gan': 'base2',\n",
    "        'seed': 0,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'leingan/ens10_tp/random/ens_mean_L1_weighted_gen_loss/', \n",
    "                       'run_number': 3                 \n",
    "                      },\n",
    "        'gan_hparams': {'generator': 'leingen',\n",
    "                        'discriminator': 'leindisc',\n",
    "                        'noise_shape' : (6, 1, 16, 16),\n",
    "                        'input_channels' : 1,\n",
    "                        'disc_lr' : 5e-5,\n",
    "                        'gen_lr' : 5e-5,\n",
    "                        'lambda_gp' : 10,\n",
    "                        'b1': 0.0, \n",
    "                        'b2': 0.9,\n",
    "                        'gen_freq' : 1, \n",
    "                        'disc_freq': 5, \n",
    "                        'disc_spectral_norm' : False,\n",
    "                        'gen_spectral_norm' : False, \n",
    "                        'loss_hparams' : {'gen_loss':\"ens_mean_L1_weighted\", 'disc_loss':'wasserstein','lambda_l1_reg': 10  },     \n",
    "                        'val_hparams' : {'val_nens':10}\n",
    "                       },\n",
    "        'train_hparams': {'epochs': 350, \n",
    "                          'gpus': 4, \n",
    "                          'batch_size': 64\n",
    "                         },\n",
    "        'data_hparams': {'train_dataset_path': \"/home/jupyter/data/saved_datasets/traindataset_ensemble_forecast_x10_tp_random_log_trans.pkl\",\n",
    "                        'valid_dataset_path': \"/home/jupyter/data/saved_datasets/validdataset_ensemble_forecast_x10_tp_random_log_trans.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/leingan_ens10_tp_random_input_ens_mean_L1_weighted_gen_loss.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725c7929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca5e9f8f",
   "metadata": {},
   "source": [
    "### Leingan with ens10 temp discriminator Spectral Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fc964aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'gan': 'base',\n",
    "        'seed': 0,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'leingan/ens10_tp/random/', \n",
    "                       'run_number': 2                       \n",
    "                      },\n",
    "        'gan_hparams': {'generator': 'leingen',\n",
    "                        'discriminator': 'leindisc',\n",
    "                        'noise_shape' : (1, 16, 16),\n",
    "                        'input_channels' : 1,\n",
    "                        'disc_lr' : 1e-4,\n",
    "                        'gen_lr' : 1e-4,\n",
    "                        'lambda_gp' : 10,\n",
    "                        'gen_freq' : 1, \n",
    "                        'disc_freq':5, \n",
    "                        'disc_spectral_norm' : True,\n",
    "                        'gen_spectral_norm' : False, \n",
    "                        'loss_type' : \"wasserstein\",     \n",
    "                        'val_hparams' : {'val_nens':10}\n",
    "                       },\n",
    "        'train_hparams': {'epochs': 200, \n",
    "                          'gpus': 4, \n",
    "                          'batch_size': 64\n",
    "                         },\n",
    "        'data_hparams': {'train_dataset_path': \"/home/jupyter/data/saved_datasets/traindataset_ensemble_forecast_x10_random_log_trans_full.pkl\",\n",
    "                        'valid_dataset_path': \"/home/jupyter/data/saved_datasets/validdataset_ensemble_forecast_x10_random_log_trans_full.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/leingan_ens10_tp_discSN_random_input.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b182c43a",
   "metadata": {},
   "source": [
    "### Leingan with ens10 tp and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c78fac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'gan': 'base',\n",
    "        'seed': 0,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'leingan/ens10_tp_with_consts/', \n",
    "                       'run_number': 0                       \n",
    "                      },\n",
    "        'gan_hparams': {'generator': 'leingen',\n",
    "                        'discriminator': 'leindisc',\n",
    "                        'noise_shape' : (1, 16, 16),\n",
    "                        'input_channels' : 12,\n",
    "                        'disc_lr' : 1e-4,\n",
    "                        'gen_lr' : 1e-4,\n",
    "                        'lambda_gp' : 10,\n",
    "                        'gen_freq' : 1, \n",
    "                        'disc_freq':5, \n",
    "                        'disc_spectral_norm' : False,\n",
    "                        'gen_spectral_norm' : False, \n",
    "                        'loss_type' : \"wasserstein\",     \n",
    "                        'val_hparams' : {'val_nens':10}\n",
    "                       },\n",
    "        'train_hparams': {'epochs': 200, \n",
    "                          'gpus': 4, \n",
    "                          'batch_size': 64\n",
    "                         },\n",
    "        'data_hparams': {'train_dataset_path': \"/home/jupyter/data/saved_datasets/traindataset_ensemble_forecast_x10_orog_lsm_log_trans_full.pkl\",\n",
    "                        'valid_dataset_path': \"/home/jupyter/data/saved_datasets/validdataset_ensemble_forecast_x10_orog_lsm_log_trans_full.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/leingan_ens10_tp_with_constants_input.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea78104",
   "metadata": {},
   "source": [
    "### Leingan with constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7f8e55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'gan': 'base',\n",
    "        'seed': 0,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'leingan/single_forecast_with_consts/', \n",
    "                       'run_number': 0                       \n",
    "                      },\n",
    "        'gan_hparams': {'generator': 'leingen',\n",
    "                        'discriminator': 'leindisc',\n",
    "                        'noise_shape' : (1, 16, 16),\n",
    "                        'input_channels' : 3,\n",
    "                        'disc_lr' : 1e-4,\n",
    "                        'gen_lr' : 1e-4,\n",
    "                        'lambda_gp' : 10,\n",
    "                        'gen_freq' : 1, \n",
    "                        'disc_freq':5, \n",
    "                        'disc_spectral_norm' : False,\n",
    "                        'gen_spectral_norm' : False, \n",
    "                        'loss_type' : \"wasserstein\",     \n",
    "                        'val_hparams' : {'val_nens':10}\n",
    "                       },\n",
    "        'train_hparams': {'epochs': 200, \n",
    "                          'gpus': 4, \n",
    "                          'batch_size': 64\n",
    "                         },\n",
    "        'data_hparams': {'train_dataset_path': \"/home/jupyter/data/saved_datasets/traindataset_single_forecast_orog_lsm_log_trans_full.pkl\",\n",
    "                        'valid_dataset_path': \"/home/jupyter/data/saved_datasets/validdataset_single_forecast_orog_lsm_log_trans_full.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/leingan_single_forecast_with_constants_input.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcddefda",
   "metadata": {},
   "source": [
    "### Leingan with constants low lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b675393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'gan': 'base',\n",
    "        'seed': 0,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'leingan/single_forecast_with_consts/', \n",
    "                       'run_number': 1                       \n",
    "                      },\n",
    "        'gan_hparams': {'generator': 'leingen',\n",
    "                        'discriminator': 'leindisc',\n",
    "                        'noise_shape' : (1, 16, 16),\n",
    "                        'input_channels' : 3,\n",
    "                        'disc_lr' : 5e-5,\n",
    "                        'gen_lr' : 5e-5,\n",
    "                        'lambda_gp' : 10,\n",
    "                        'gen_freq' : 1, \n",
    "                        'disc_freq':5, \n",
    "                        'disc_spectral_norm' : False,\n",
    "                        'gen_spectral_norm' : False, \n",
    "                        'loss_type' : \"wasserstein\",     \n",
    "                        'val_hparams' : {'val_nens':10}\n",
    "                       },\n",
    "        'train_hparams': {'epochs': 200, \n",
    "                          'gpus': 4, \n",
    "                          'batch_size': 64\n",
    "                         },\n",
    "        'data_hparams': {'train_dataset_path': \"/home/jupyter/data/saved_datasets/traindataset_single_forecast_orog_lsm_log_trans_full.pkl\",\n",
    "                        'valid_dataset_path': \"/home/jupyter/data/saved_datasets/validdataset_single_forecast_orog_lsm_log_trans_full.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/leingan_single_forecast_with_constants_input_low_lr.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7848101",
   "metadata": {},
   "source": [
    "### Leingan ensemble x10 tp with extra variables: column water, temperature, convective inhbition, convective avail potential energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3589a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'gan': 'base',\n",
    "        'seed': 0,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'leingan/ens10_tp_added_vars_TCW-T-CAPE-CIN/random/', \n",
    "                       'run_number': 0                       \n",
    "                      },\n",
    "        'gan_hparams': {'generator': 'leingen',\n",
    "                        'discriminator': 'leindisc',\n",
    "                        'noise_shape' : (1, 16, 16),\n",
    "                        'input_channels' : 5,\n",
    "                        'disc_lr' : 1e-5,\n",
    "                        'gen_lr' : 1e-5,\n",
    "                        'lambda_gp' : 10,\n",
    "                        'gen_freq' : 1, \n",
    "                        'disc_freq':5, \n",
    "                        'disc_spectral_norm' : False,\n",
    "                        'gen_spectral_norm' : False, \n",
    "                        'loss_type' : \"wasserstein\",     \n",
    "                        'val_hparams' : {'val_nens':10}\n",
    "                       },\n",
    "        'train_hparams': {'epochs': 500, \n",
    "                          'gpus': 2, \n",
    "                          'batch_size': 64\n",
    "                         },\n",
    "        'data_hparams': {'train_dataset_path': \"/home/jupyter/data/saved_datasets/traindataset_ensemble_forecast_x10_random_extra_vars_TCW-T-CAPE-CIN_log_trans.pkl\",\n",
    "                        'valid_dataset_path': \"/home/jupyter/data/saved_datasets/validdataset_ensemble_forecast_x10_random_extra_vars_TCW-T-CAPE-CIN_log_trans.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/leingan_ens10_tp_random_added_vars_TCW-T-CAPE-CIN.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e990a0a4",
   "metadata": {},
   "source": [
    "### Leingan single forcast tpwith extra variables: column water, temperature, convective inhbition, convective avail potential energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "729af5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "args = {'gan': 'base',\n",
    "        'seed': 0,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'leingan/single_forecast_tp_added_vars_TCW-T-CAPE-CIN/', \n",
    "                       'run_number': 2                       \n",
    "                      },\n",
    "        'gan_hparams': {'generator': 'leingen',\n",
    "                        'discriminator': 'leindisc',\n",
    "                        'noise_shape' : (1, 16, 16),\n",
    "                        'input_channels' : 5,\n",
    "                        'disc_lr' : 1e-5,\n",
    "                        'gen_lr' : 1e-5,\n",
    "                        'lambda_gp' : 10,\n",
    "                        'gen_freq' : 1, \n",
    "                        'disc_freq':5, \n",
    "                        'disc_spectral_norm' : False,\n",
    "                        'gen_spectral_norm' : False, \n",
    "                        'loss_type' : \"wasserstein\",     \n",
    "                        'val_hparams' : {'val_nens':10}\n",
    "                       },\n",
    "        'train_hparams': {'epochs':500, \n",
    "                          'gpus': 4, \n",
    "                          'batch_size': 64\n",
    "                         },\n",
    "        'data_hparams': {'train_dataset_path': \"/home/jupyter/data/saved_datasets/traindataset_single_forecast_tp_extra_vars_TCW-T-CAPE-CIN_log_trans.pkl\",\n",
    "                        'valid_dataset_path': \"/home/jupyter/data/saved_datasets/validdataset_single_forecast_tp_extra_vars_TCW-T-CAPE-CIN_log_trans.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/leingan_single_forecast_tp_added_vars_TCW-T-CAPE-CIN.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b78113",
   "metadata": {},
   "source": [
    "### Leingan single forcast tpwith extra variables: column water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5067b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "args = {'gan': 'base',\n",
    "        'seed': 0,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'leingan/single_forecast_tp_added_vars_TCW/', \n",
    "                       'run_number': 1                       \n",
    "                      },\n",
    "        'gan_hparams': {'generator': 'leingen',\n",
    "                        'discriminator': 'leindisc',\n",
    "                        'noise_shape' : (1, 16, 16),\n",
    "                        'input_channels' : 2,\n",
    "                        'disc_lr' : 5e-5,\n",
    "                        'gen_lr' : 5e-5,\n",
    "                        'lambda_gp' : 10,\n",
    "                        'gen_freq' : 1, \n",
    "                        'disc_freq':5, \n",
    "                        'disc_spectral_norm' : False,\n",
    "                        'gen_spectral_norm' : False, \n",
    "                        'loss_type' : \"wasserstein\",     \n",
    "                        'val_hparams' : {'val_nens':10}\n",
    "                       },\n",
    "        'train_hparams': {'epochs':300, \n",
    "                          'gpus': 3, \n",
    "                          'batch_size': 64\n",
    "                         },\n",
    "        'data_hparams': {'train_dataset_path': \"/home/jupyter/data/saved_datasets/traindataset_single_forecast_tp_extra_vars_TCW_log_trans.pkl\",\n",
    "                        'valid_dataset_path': \"/home/jupyter/data/saved_datasets/validdataset_single_forecast_tp_extra_vars_TCW_log_trans.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/leingan_single_forecast_tp_added_vars_TCW.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d554a6",
   "metadata": {},
   "source": [
    "### Leingan single forcast super resolution pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8be9473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "args = {'gan': 'base2',\n",
    "        'seed': 0,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'leingan/single_forecast_tp_pure_sr_pretraining/', \n",
    "                       'run_number': 0                       \n",
    "                      },\n",
    "        'gan_hparams': {'generator': 'leingen',\n",
    "                        'discriminator': 'leindisc',\n",
    "                        'noise_shape' : (1, 16, 16),\n",
    "                        'zero_noise': True,\n",
    "                        'input_channels' : 1,\n",
    "                        'disc_lr' : 5e-5,\n",
    "                        'gen_lr' : 5e-5,\n",
    "                        'lambda_gp' : 10,\n",
    "                        'b1': 0.0, \n",
    "                        'b2': 0.9,\n",
    "                        'gen_freq' : 1, \n",
    "                        'disc_freq':5, \n",
    "                        'disc_spectral_norm' : False,\n",
    "                        'gen_spectral_norm' : False, \n",
    "                        'loss_hparams' : {'gen_loss':\"wasserstein\", 'disc_loss':'wasserstein','lambda_l1_reg': 0},     \n",
    "                        'val_hparams' : {'val_nens':10}\n",
    "                       },\n",
    "        'train_hparams': {'epochs':200, \n",
    "                          'gpus': 4, \n",
    "                          'batch_size': 64\n",
    "                         },\n",
    "        'data_hparams': {'train_dataset_path': \"/home/jupyter/data/saved_datasets/traindataset_single_forecast_tp_pure_sr_log_trans.pkl\",\n",
    "                        'valid_dataset_path': \"/home/jupyter/data/saved_datasets/validdataset_single_forecast_tp_pure_sr_log_trans.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/leingan_single_forecast_tp_pure_sr_pretraining.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9566e552",
   "metadata": {},
   "source": [
    "### Leingan ens10 random finetuning post sr_pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e02be06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "args = {'gan': 'base2',\n",
    "        'seed': 0,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'leingan/ens10_tp/random/post_sr_finetuning/', \n",
    "                       'run_number': 0                       \n",
    "                      },\n",
    "        'gan_hparams': {'generator': 'leingen',\n",
    "                        'discriminator': 'leindisc',\n",
    "                        'noise_shape' : (1, 16, 16),\n",
    "                        'zero_noise': False,\n",
    "                        'input_channels' : 1,\n",
    "                        'disc_lr' : 1e-5,\n",
    "                        'gen_lr' : 1e-5,\n",
    "                        'lambda_gp' : 10,\n",
    "                        'b1': 0.0, \n",
    "                        'b2': 0.9,\n",
    "                        'gen_freq' : 1, \n",
    "                        'disc_freq': 5, \n",
    "                        'disc_spectral_norm' : False,\n",
    "                        'gen_spectral_norm' : False, \n",
    "                        'loss_hparams' : {'gen_loss':\"wasserstein\", 'disc_loss':'wasserstein','lambda_l1_reg': 0},     \n",
    "                        'val_hparams' : {'val_nens':10}\n",
    "                       },\n",
    "        'train_hparams': {'epochs':400, \n",
    "                          'gpus':4, \n",
    "                          'batch_size': 64\n",
    "                         },\n",
    "        'data_hparams': {'train_dataset_path': \"/home/jupyter/data/saved_datasets/traindataset_ensemble_forecast_x10_tp_random_log_trans.pkl\",\n",
    "                        'valid_dataset_path': \"/home/jupyter/data/saved_datasets/validdataset_ensemble_forecast_x10_tp_random_log_trans.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/leingan_ens10_tp_random_finetuning.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5805e162",
   "metadata": {},
   "source": [
    "### BroadLeingan with extra variables: column water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adb7ca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "args = {'gan': 'base2',\n",
    "        'seed': 0,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'broadleingan/ens10_tp_added_vars_TCW/random/', \n",
    "                       'run_number': 7               \n",
    "                      },\n",
    "        'gan_hparams': {'generator': 'broadleingen',\n",
    "                        'discriminator': 'broadleindisc',\n",
    "                        'noise_shape' : (1, 16, 16),\n",
    "                        'zero_noise': False,\n",
    "                        'input_channels' : 2,\n",
    "                        'opt_hparams': {'gen_optimiser':'adam', 'disc_optimiser':'adam', \n",
    "                                        'disc_lr' : 5e-5, 'gen_lr': 5e-5, 'gen_freq' : 1, \n",
    "                                        'disc_freq':5, 'b1':0.0, 'b2' : 0.9},\n",
    "                        'disc_spectral_norm' : False,\n",
    "                        'gen_spectral_norm' : False, \n",
    "                        'loss_hparams' : {'gen_loss':\"wasserstein\", 'disc_loss':'wasserstein','lambda_l1_reg': 0, 'lambda_gp':10},     \n",
    "                        'val_hparams' : {'val_nens':10}\n",
    "                       },\n",
    "        'train_hparams': {'epochs':400, \n",
    "                          'gpus':4, \n",
    "                          'batch_size': 64\n",
    "                         },\n",
    "        'data_hparams': {'train_dataset_path': \"/home/jupyter/data/saved_datasets/traindataset_ensemble_forecast_x10_random_extra_vars_TCW_log_trans_padded_24.pkl\",\n",
    "                        'valid_dataset_path': \"/home/jupyter/data/saved_datasets/validdataset_ensemble_forecast_x10_random_extra_vars_TCW_log_trans_padded_24.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/broadleingan_ens10_tp_random_added_vars_TCW.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4c95e3",
   "metadata": {},
   "source": [
    "### BroadLeingan ens10 tp random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81d65df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "args = {'gan': 'base2',\n",
    "        'seed': 0,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'broadleingan/ens10_tp/random/', \n",
    "                       'run_number': 2         \n",
    "                      },\n",
    "        'gan_hparams': {'generator': 'broadleingen',\n",
    "                        'discriminator': 'broadleindisc',\n",
    "                        'noise_shape' : (1, 16, 16),\n",
    "                        'zero_noise': False,\n",
    "                        'input_channels' : 1,\n",
    "                        'opt_hparams': {'gen_optimiser':'adam', 'disc_optimiser':'adam', \n",
    "                                        'disc_lr' : 5e-6, 'gen_lr': 5e-6, 'gen_freq' : 1, \n",
    "                                        'disc_freq':5, 'b1':0.0, 'b2' : 0.9, \n",
    "                                         'gen_momentum': 0.9, 'disc_momentum': 0.9},\n",
    "                        'disc_spectral_norm' : False,\n",
    "                        'gen_spectral_norm' : False, \n",
    "                        'loss_hparams' : {'gen_loss':\"wasserstein\", 'disc_loss':'wasserstein','lambda_l1_reg': 0, 'lambda_gp':10},     \n",
    "                        'val_hparams' : {'val_nens':10}\n",
    "                       },\n",
    "        'train_hparams': {'epochs':1000, \n",
    "                          'gpus':4, \n",
    "                          'batch_size': 64\n",
    "                         },\n",
    "        'data_hparams': {'train_dataset_path': \"/home/jupyter/data/saved_datasets/traindataset_ensemble_forecast_x10_random_log_trans_padded_24.pkl\",\n",
    "                        'valid_dataset_path': \"/home/jupyter/data/saved_datasets/validdataset_ensemble_forecast_x10_random_log_trans_padded_24.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/broadleingan_ens10_tp_random.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5d4d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa0ad22c",
   "metadata": {},
   "source": [
    "### Leingan with broadfield channel and extra variables: total column water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e8b51a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "args = {'gan': 'base2',\n",
    "        'seed': 0,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'leingan/single_forecast_tp_broadfield_channel_added_vars_TCW/', \n",
    "                       'run_number': 1              \n",
    "                      },\n",
    "        'gan_hparams': {'generator': 'leingen',\n",
    "                        'discriminator': 'leindisc',\n",
    "                        'noise_shape' : (1, 16, 16),\n",
    "                        'zero_noise': False,\n",
    "                        'input_channels' : 3,\n",
    "                        'opt_hparams': {'gen_optimiser':'adam', 'disc_optimiser':'adam', \n",
    "                                        'disc_lr' : 1e-5, 'gen_lr': 1e-5, 'gen_freq' : 1, \n",
    "                                        'disc_freq':5, 'b1':0.0, 'b2' : 0.9},\n",
    "                        'disc_spectral_norm' : False,\n",
    "                        'gen_spectral_norm' : False, \n",
    "                        'loss_hparams' : {'gen_loss':\"wasserstein\", 'disc_loss':'wasserstein','lambda_l1_reg': 0, 'lambda_gp':10},     \n",
    "                        'val_hparams' : {'val_nens':10}\n",
    "                       },\n",
    "        'train_hparams': {'epochs':1000, \n",
    "                          'gpus':4, \n",
    "                          'batch_size': 64\n",
    "                         },\n",
    "        'data_hparams': {'train_dataset_path': \"/home/jupyter/data/saved_datasets/traindataset_single_forecast_tp_extra_vars_TCW_log_trans_padded_10_channel.pkl\",\n",
    "                        'valid_dataset_path': \"/home/jupyter/data/saved_datasets/validdataset_single_forecast_tp_extra_vars_TCW_log_trans_padded_10_channel.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/leingan_single_forecast_tp_broadfield_channel_added_vars_TCW.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f7c710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9dccf05b",
   "metadata": {},
   "source": [
    "### Leingan with broadfield channel and extra variables: total column water (ensemble) - with ens mean l1 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55545b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "args = {'gan': 'base2',\n",
    "        'seed': 0,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'leingan/ens10_tp_and_added_vars_TCW_broadfield_channel/', \n",
    "                       'run_number': 4             \n",
    "                      },\n",
    "        'gan_hparams': {'generator': 'leingen2',\n",
    "                        'discriminator': 'leindisc',\n",
    "                        'noise_shape' : (6, 1, 16, 16),\n",
    "                        'zero_noise': False,\n",
    "                        'input_channels' : 3,\n",
    "                        'opt_hparams': {'gen_optimiser':'adam', 'disc_optimiser':'adam', \n",
    "                                        'disc_lr' : 1e-5, 'gen_lr': 1e-5, 'gen_freq' : 1, \n",
    "                                        'disc_freq':5, 'b1':0.0, 'b2' : 0.9},\n",
    "                        'disc_spectral_norm' : False,\n",
    "                        'gen_spectral_norm' : False, \n",
    "                        'loss_hparams' : {'gen_loss':\"ens_mean_L1_weighted\", 'disc_loss':'wasserstein','lambda_l1_reg': 10, 'lambda_gp':10},     \n",
    "                        'val_hparams' : {'val_nens':10}\n",
    "                       },\n",
    "        'train_hparams': {'epochs':500, \n",
    "                          'gpus':4, \n",
    "                          'batch_size': 64\n",
    "                         },\n",
    "        'data_hparams': {'train_dataset_path': \"/home/jupyter/data/saved_datasets/traindataset_ensemble_tp_extra_vars_TCW_x10_log_trans_padded_10_channel.pkl\",\n",
    "                        'valid_dataset_path': \"/home/jupyter/data/saved_datasets/validdataset_ensemble_tp_extra_vars_TCW_x10_log_trans_padded_10_channel.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/leingan_ens10_tp_and_added_vars_TCW_broadfield_channel.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c70537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "args = {'gan': 'base2',\n",
    "        'seed': 0,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'leingan/ens10_tp_and_added_vars_TCW_broadfield_channel/', \n",
    "                       'run_number': 3             \n",
    "                      },\n",
    "        'gan_hparams': {'generator': 'leingen2',\n",
    "                        'discriminator': 'leindisc',\n",
    "                        'noise_shape' : (6, 1, 16, 16),\n",
    "                        'zero_noise': False,\n",
    "                        'input_channels' : 3,\n",
    "                        'opt_hparams': {'gen_optimiser':'adam', 'disc_optimiser':'adam', \n",
    "                                        'disc_lr' : 1e-5, 'gen_lr': 1e-5, 'gen_freq' : 1, \n",
    "                                        'disc_freq':5, 'b1':0.0, 'b2' : 0.9},\n",
    "                        'disc_spectral_norm' : False,\n",
    "                        'gen_spectral_norm' : False, \n",
    "                        'loss_hparams' : {'gen_loss':\"ens_mean_L1_weighted\", 'disc_loss':'wasserstein','lambda_l1_reg': 10, 'lambda_gp':10},     \n",
    "                        'val_hparams' : {'val_nens':10}\n",
    "                       },\n",
    "        'train_hparams': {'epochs':500, \n",
    "                          'gpus':4, \n",
    "                          'batch_size': 64\n",
    "                         },\n",
    "        'data_hparams': {'train_dataset_path': \"/home/jupyter/data/saved_datasets/traindataset_ensemble_tp_extra_vars_TCW_x10_log_trans_padded_10_channel.pkl\",\n",
    "                        'valid_dataset_path': \"/home/jupyter/data/saved_datasets/validdataset_ensemble_tp_extra_vars_TCW_x10_log_trans_padded_10_channel.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/leingan_ens10_tp_and_added_vars_TCW_broadfield_channel.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295e8167",
   "metadata": {},
   "source": [
    "### Leingan (no log trans) with broadfield channel and extra variables: total column water (ensemble) - with ens mean l1 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ba31b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "args = {'gan': 'base2',\n",
    "        'seed': 0,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'leingan/ens10_tp_and_added_vars_TCW_broadfield_channel/no_log_trans/', \n",
    "                       'run_number': 0            \n",
    "                      },\n",
    "        'gan_hparams': {'generator': 'leingen2',\n",
    "                        'discriminator': 'leindisc',\n",
    "                        'noise_shape' : (6, 1, 16, 16),\n",
    "                        'zero_noise': False,\n",
    "                        'input_channels' : 3,\n",
    "                        'opt_hparams': {'gen_optimiser':'adam', 'disc_optimiser':'adam', \n",
    "                                        'disc_lr' : 5e-5, 'gen_lr': 5e-5, 'gen_freq' : 1, \n",
    "                                        'disc_freq':5, 'b1':0.0, 'b2' : 0.9},\n",
    "                        'disc_spectral_norm' : False,\n",
    "                        'gen_spectral_norm' : False, \n",
    "                        'loss_hparams' : {'gen_loss':\"ens_mean_L1_weighted\", 'disc_loss':'wasserstein','lambda_l1_reg': 10, 'lambda_gp':10},     \n",
    "                        'val_hparams' : {'val_nens':10}\n",
    "                       },\n",
    "        'train_hparams': {'epochs':500, \n",
    "                          'gpus':4, \n",
    "                          'batch_size': 64\n",
    "                         },\n",
    "        'data_hparams': {'train_dataset_path': \"/home/jupyter/data/saved_datasets/traindataset_ensemble_tp_extra_vars_TCW_x10_padded_10_channel.pkl\",\n",
    "                        'valid_dataset_path': \"/home/jupyter/data/saved_datasets/validdataset_ensemble_tp_extra_vars_TCW_x10_padded_10_channel.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/leingan_ens10_tp__no_log_trans_and_added_vars_TCW_broadfield_channel.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd13539",
   "metadata": {},
   "source": [
    "### Stylegan Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f1e4f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "args = {'gan': 'stylegan',\n",
    "        'seed': 0,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'stylegan/unconditional/', \n",
    "                       'run_number': 6\n",
    "                      },\n",
    "        'train_hparams': {'epochs':100, \n",
    "                          'gpus':1, \n",
    "                          'batch_size':32\n",
    "                         },\n",
    "        'data_hparams': {'train_dataset_path': \"/home/jupyter/data/saved_datasets/traindataset_ensemble_tp_extra_vars_TCW_x10_log_trans_padded_10_channel.pkl\",\n",
    "                        'valid_dataset_path': \"/home/jupyter/data/saved_datasets/validdataset_ensemble_tp_extra_vars_TCW_x10_log_trans_padded_10_channel.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/stylegan_test.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8531cf53",
   "metadata": {},
   "source": [
    "### Stylegan inspired leingan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18c46008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "args = {'gan': 'base2',\n",
    "        'seed': 0,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'leinstylegan/ens10_tp_and_added_vars_TCW_broadfield_channel/wasserstein/', \n",
    "                       'run_number': 12\n",
    "                      },\n",
    "        'gan_hparams': {'generator': 'leinstylegen',\n",
    "                        'discriminator': 'leinstyledisc',\n",
    "                        'noise_shape' : (1, 16, 16),\n",
    "                        'zero_noise': False,\n",
    "                        'input_channels' : 3,\n",
    "                        'opt_hparams': {'gen_optimiser':'adam', 'disc_optimiser':'adam', \n",
    "                                        'disc_lr' : 1e-3, 'gen_lr': 1e-3, 'gen_freq' : 1, \n",
    "                                        'disc_freq':5, 'b1':0.0, 'b2' : 0.9},\n",
    "                        'disc_spectral_norm' : False,\n",
    "                        'gen_spectral_norm' : False, \n",
    "                        'loss_hparams' : {'gen_loss':\"wasserstein\", 'disc_loss':'wasserstein','lambda_l1_reg': 0, 'lambda_gp':10},     \n",
    "                        'val_hparams' : {'val_nens':10}\n",
    "                       },\n",
    "        'train_hparams': {'epochs':500, \n",
    "                          'gpus':[0,1,2,3], \n",
    "                          'batch_size': 64\n",
    "                         },\n",
    "        'data_hparams': {'train_dataset_path': \"/home/jupyter/data/saved_datasets/traindataset_ensemble_tp_extra_vars_TCW_x10_log_trans_padded_10_channel.pkl\",\n",
    "                        'valid_dataset_path': \"/home/jupyter/data/saved_datasets/validdataset_ensemble_tp_extra_vars_TCW_x10_log_trans_padded_10_channel.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/leinstylegan_ens10_tp_and_added_vars_TCW_broadfield_channel.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4ff57ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "args = {'gan': 'base2',\n",
    "        'seed': 0,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'leinstylegan/ens10_tp_and_added_vars_TCW_broadfield_channel/wasserstein/with_modulation/', \n",
    "                       'run_number': 9      \n",
    "                      },\n",
    "        'gan_hparams': {'generator': 'leinstylegen2',\n",
    "                        'discriminator': 'leinstyledisc',\n",
    "                        'noise_shape' : (1, 16, 16),\n",
    "                        'zero_noise': False,\n",
    "                        'input_channels' : 3,\n",
    "                        'opt_hparams': {'gen_optimiser':'adam', 'disc_optimiser':'adam', \n",
    "                                        'disc_lr' : 1e-5, 'gen_lr': 1e-5, 'gen_freq' : 1, \n",
    "                                        'disc_freq':5, 'b1':0.0, 'b2' : 0.9},\n",
    "                        'disc_spectral_norm' : False,\n",
    "                        'gen_spectral_norm' : False, \n",
    "                        'loss_hparams' : {'gen_loss':\"wasserstein\", 'disc_loss':'wasserstein','lambda_l1_reg': 0, 'lambda_gp':10},     \n",
    "                        'val_hparams' : {'val_nens':10}\n",
    "                       },\n",
    "        'train_hparams': {'epochs':500, \n",
    "                          'gpus':[0,1,2,3], \n",
    "                          'batch_size': 64\n",
    "                         },\n",
    "        'data_hparams': {'train_dataset_path': \"/home/jupyter/data/saved_datasets/traindataset_ensemble_tp_extra_vars_TCW_x10_log_trans_padded_10_channel.pkl\",\n",
    "                        'valid_dataset_path': \"/home/jupyter/data/saved_datasets/validdataset_ensemble_tp_extra_vars_TCW_x10_log_trans_padded_10_channel.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/leinstylegan_ens10_tp_and_added_vars_TCW_broadfield_channel.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ea4802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "args = {'gan': 'base2',\n",
    "        'seed': 0,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'pricestylegan/ens10_tp_and_added_vars_TCW_broadfield_channel/wasserstein/', \n",
    "                       'run_number': 10\n",
    "                      },\n",
    "        'gan_hparams': {'generator': 'pricestylegen',\n",
    "                        'discriminator': 'leindisc',\n",
    "                        'noise_shape' : (1, 16, 16),\n",
    "                        'zero_noise': False,\n",
    "                        'input_channels' : 3,\n",
    "                        'opt_hparams': {'gen_optimiser':'adam', 'disc_optimiser':'adam', \n",
    "                                        'disc_lr' : 1e-4, 'gen_lr': 1e-4, 'gen_freq' : 1, \n",
    "                                        'disc_freq':5, 'b1':0.0, 'b2' : 0.9},\n",
    "                        'disc_spectral_norm' : False,\n",
    "                        'gen_spectral_norm' : False, \n",
    "                        'loss_hparams' : {'gen_loss':\"wasserstein\", 'disc_loss':'wasserstein','lambda_l1_reg': 0, 'lambda_gp':10},     \n",
    "                        'val_hparams' : {'val_nens':10}\n",
    "                       },\n",
    "        'train_hparams': {'epochs':500, \n",
    "                          'gpus':[0,1,2,3], \n",
    "                          'batch_size': 64\n",
    "                         },\n",
    "        'data_hparams': {'train_dataset_path': \"/home/jupyter/data/saved_datasets/traindataset_ensemble_tp_extra_vars_TCW_x10_log_trans_padded_10_channel.pkl\",\n",
    "                        'valid_dataset_path': \"/home/jupyter/data/saved_datasets/validdataset_ensemble_tp_extra_vars_TCW_x10_log_trans_padded_10_channel.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/pricestylegan_ens10_tp_and_added_vars_TCW_broadfield_channel.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eb9d05",
   "metadata": {},
   "source": [
    "# Eval args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612e52dd",
   "metadata": {},
   "source": [
    "### Leingan with extra variables: column water, temperature, convective inhbition, convective avail potential energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6bfeb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'gan': 'base',\n",
    "        'seed': 0,\n",
    "        'gpu':0,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'leingan/ens10_tp_added_vars_TCW-T-CAPE-CIN/random/', \n",
    "                       'run_number': 0                       \n",
    "                      },\n",
    "        'model_path': '/home/jupyter/data/saved_models/leingan/ens10_random_tp_added_vars_TCW-T-CAPE-CIN/0/epoch=499-step=322499.ckpt',\n",
    "        'eval_hparams': {'batch_size': 128, \n",
    "                         'num_ens': 30\n",
    "                         },\n",
    "        'data_hparams': {'test_dataset_path': \"/home/jupyter/data/saved_datasets/testdataset_ensemble_forecast_x10_random_extra_vars_TCW-T-CAPE-CIN_log_trans_first_days_5.pkl\",\n",
    "                        }\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/eval_leingan_ens10_tp_random_added_vars_TCW-T-CAPE-CIN.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517cb217",
   "metadata": {},
   "source": [
    "### Leingan with extra variables: column water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d30002d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'gan': 'base',\n",
    "        'seed': 0,\n",
    "        'gpu':0,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'leingan/single_forecast_tp_added_vars_TCW/', \n",
    "                       'run_number': 1                       \n",
    "                      },\n",
    "        'model_path': '/home/jupyter/data/saved_models/leingan/single_forecast_tp_added_vars_TCW/1/epoch=299-step=196499.ckpt',\n",
    "        'eval_hparams': {'batch_size': 128, \n",
    "                         'num_ens': 30\n",
    "                         },\n",
    "        'data_hparams': {'test_dataset_path': \"/home/jupyter/data/saved_datasets/testdataset_single_forecast_tp_extra_vars_TCW_log_trans_first_days_5.pkl\",\n",
    "                        }\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/eval_leingan_single_forecast_tp_added_vars_TCW.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03395d67",
   "metadata": {},
   "source": [
    "### Leingan with ens10 tp stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91dfacbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'gan': 'base',\n",
    "        'seed': 0,\n",
    "        'gpu':0,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'leingan/ens10_tp/stacked/', \n",
    "                       'run_number': 0                       \n",
    "                      },\n",
    "        'model_path': '/home/jupyter/data/saved_models/leingan/ens10_tp/stacked/0/epoch=149-step=100499.ckpt',\n",
    "        'eval_hparams': {'batch_size': 128, \n",
    "                         'num_ens': 30\n",
    "                         },\n",
    "        'data_hparams': {'test_dataset_path': \"/home/jupyter/data/saved_datasets/testdataset_ensemble_forecast_x10_tp_stacked_log_trans_first_days_5.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/eval_leingan_ens10_tp_stacked_input.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861f952d",
   "metadata": {},
   "source": [
    "### Leingan with ens10 tp random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efc8675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'gan': 'base',\n",
    "        'seed': 0,\n",
    "        'gpu':1,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'leingan/ens10_tp/random/', \n",
    "                       'run_number': 1                       \n",
    "                      },\n",
    "        'model_path': '/home/jupyter/data/saved_models/leingan/ens10_tp/random/1/epoch=199-step=133999.ckpt',\n",
    "        'eval_hparams': {'batch_size': 128, \n",
    "                         'num_ens': 30\n",
    "                         },\n",
    "        'data_hparams': {'test_dataset_path': \"/home/jupyter/data/saved_datasets/testdataset_ensemble_forecast_x10_tp_random_log_trans_first_days_5.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/eval_leingan_ens10_tp_random_input.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21deb766",
   "metadata": {},
   "source": [
    "### Leingan with single forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecd2b745",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'gan': 'base',\n",
    "        'seed': 0,\n",
    "        'gpu':2,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'leingan/single_forecast/', \n",
    "                       'run_number': 0                       \n",
    "                      },\n",
    "        'model_path': '/home/jupyter/data/saved_models/leingan/single_forecast/0/epoch=120-step=324279.ckpt',\n",
    "        'eval_hparams': {'batch_size': 128, \n",
    "                         'num_ens': 30\n",
    "                         },\n",
    "        'data_hparams': {'test_dataset_path': \"/home/jupyter/data/saved_datasets/testdataset_single_forecast_tp_log_trans_first_days_5.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/eval_leingan_single_forecast_tp_input.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7f604e",
   "metadata": {},
   "source": [
    "### Leingan with single forecast with constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abb5bae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'gan': 'base',\n",
    "        'seed': 0,\n",
    "        'gpu':3,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'leingan/single_forecast_with_consts/', \n",
    "                       'run_number': 1                       \n",
    "                      },\n",
    "        'model_path': '/home/jupyter/data/saved_models/leingan/single_forecast_with_consts/1/epoch=199-step=133999.ckpt',\n",
    "        'eval_hparams': {'batch_size': 128, \n",
    "                         'num_ens': 30\n",
    "                         },\n",
    "        'data_hparams': {'test_dataset_path': \"/home/jupyter/data/saved_datasets/testdataset_single_forecast_tp_orog_lsm_log_trans_first_days_5.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/eval_leingan_single_forecast_tp_with_consts_input.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4187a23",
   "metadata": {},
   "source": [
    "### wgan-gp single forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "570e52b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'gan': 'wgan-gp',\n",
    "        'seed': 0,\n",
    "        'gpu':0,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'wgan-gp/', \n",
    "                       'run_number': 0                       \n",
    "                      },\n",
    "        'model_path': '/home/jupyter/data/saved_models/wgan-gp/0/epoch=124-step=334999.ckpt',\n",
    "        'eval_hparams': {'batch_size': 128, \n",
    "                         'num_ens': 30\n",
    "                         },\n",
    "        'data_hparams': {'test_dataset_path': \"/home/jupyter/data/saved_datasets/testdataset_single_forecast_tp_log_trans_first_days_5.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/eval_wgan-gp_single_forecast_tp.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ee1093",
   "metadata": {},
   "source": [
    "### wgan-gp-smoothed single forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54a9714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'gan': 'wgan-gp',\n",
    "        'seed': 0,\n",
    "        'gpu':1,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'wgan-gp-smoothed/', \n",
    "                       'run_number': 0                       \n",
    "                      },\n",
    "        'model_path': '/home/jupyter/data/saved_models/wgan-gp-smoothed/0/epoch=123-step=332319.ckpt',\n",
    "        'eval_hparams': {'batch_size': 128, \n",
    "                         'num_ens': 30\n",
    "                         },\n",
    "        'data_hparams': {'test_dataset_path': \"/home/jupyter/data/saved_datasets/testdataset_single_forecast_tp_log_trans_first_days_5.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/eval_wgan-gp-smoothed_single_forecast_tp.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc62174",
   "metadata": {},
   "source": [
    "### Broadleingan single forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa6c2e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'gan': 'leingan',\n",
    "        'seed': 0,\n",
    "        'gpu':2,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'broadleingan/', \n",
    "                       'run_number': 0                       \n",
    "                      },\n",
    "        'model_path': '/home/jupyter/data/saved_models/broadleingan/0/epoch=343-step=358791.ckpt',\n",
    "        'eval_hparams': {'batch_size': 128, \n",
    "                         'num_ens': 30\n",
    "                         },\n",
    "        'data_hparams': {'test_dataset_path': \"/home/jupyter/data/saved_datasets/testdataset_single_forecast_only_log_trans_.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/eval_broadleingan_single_forecast_tp_input.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ab574c",
   "metadata": {},
   "source": [
    "### Leingan with ens10 tp random - gen loss: ens_mean_L1_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24695596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "args = {'gan': 'base2',\n",
    "        'seed': 0,\n",
    "        'gpu':1,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'leingan/ens10_tp/random/ens_mean_L1_weighted_gen_loss/', \n",
    "                       'run_number': 3                       \n",
    "                      },\n",
    "        'model_path': '/home/jupyter/data/saved_models/leingan/ens10_tp/random/ens_mean_L1_weighted_gen_loss/3/epoch=349-step=234499.ckpt',\n",
    "        'eval_hparams': {'batch_size': 128, \n",
    "                         'num_ens': 30\n",
    "                         },\n",
    "        'data_hparams': {'test_dataset_path': \"/home/jupyter/data/saved_datasets/testdataset_ensemble_forecast_x10_tp_random_log_trans_first_days_5.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/eval_leingan_ens10_tp_random_input_ens_mean_L1_weighted_gen_loss.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bfbebb",
   "metadata": {},
   "source": [
    "### Leingan super-resolution eval with ens10 tp stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc174b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "args = {'gan': 'base2',\n",
    "        'seed': 0,\n",
    "        'gpu':1,\n",
    "        'super_resolution': True,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'leingan/single_forecast_tp_pure_sr_pretraining/', \n",
    "                       'run_number': 0                       \n",
    "                      },\n",
    "        'model_path': '/home/jupyter/data/saved_models/leingan/single_forecast_tp_pure_sr_pretraining/0/epoch=199-step=133999.ckpt',\n",
    "        'eval_hparams': {'batch_size': 128, \n",
    "                         'num_ens': 10\n",
    "                         },\n",
    "        'data_hparams': {'test_dataset_path': \"/home/jupyter/data/saved_datasets/testdataset_ensemble_forecast_x10_tp_stacked_log_trans_first_days_5.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/eval_leingan_pure_sr_on_ens10_tp_stacked.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ced478",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df420677",
   "metadata": {},
   "source": [
    "### Leingan with broadfield channel and extra variables: total column water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fcf18f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "args = {'gan': 'base2',\n",
    "        'seed': 0,\n",
    "        'gpu': 0,\n",
    "        'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "                       'run_name': 'leingan/single_forecast_tp_broadfield_channel_added_vars_TCW/', \n",
    "                       'run_number': 1               \n",
    "                      },\n",
    "        'model_path': '/home/jupyter/data/saved_models/leingan/single_forecast_tp_broadfield_channel_added_vars_TCW/1/epoch=919-step=477479.ckpt',\n",
    "        'eval_hparams': {'batch_size': 128, \n",
    "                         'num_ens': 30\n",
    "                         },\n",
    "        'data_hparams': {'test_dataset_path': \"/home/jupyter/data/saved_datasets/testdataset_single_forecast_tp_extra_vars_TCW_log_trans_padded_10_channel_first_days_5.pkl\"}\n",
    "        \n",
    "}\n",
    "\n",
    "json.dump(args, open('../experiments/eval_leingan_single_forecast_tp_broadfield_channel_added_vars_TCW.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b63eb19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403815e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea37a4b5",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ce0d8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = {'gan': 'base',\n",
    "#         'seed': 0,\n",
    "#         'save_hparams':{'save_dir': '/home/jupyter/data/saved_models/', \n",
    "#                        'run_name': 'leingan/ens10_temperature/', \n",
    "#                        'run_number': 0                       \n",
    "#                       },\n",
    "#         'model_path': '/home/jupyter/data/saved_models/leingan/ens10_temperature/0/epoch=149-step=100499.ckpt',\n",
    "#         'eval_hparams': {'batch_size': 128, \n",
    "#                          'num_ens': 50\n",
    "#                          },\n",
    "#         'data_hparams': {'test_dataset_path': \"/home/jupyter/data/saved_datasets/testdataset_ensemble_forecast_x10_log_trans_sample.pkl\"}\n",
    "        \n",
    "# }\n",
    "\n",
    "# json.dump(args, open('../experiments/eval_test.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a061601b",
   "metadata": {},
   "source": [
    "# Models to eval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d893a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "models = {1: '/home/jupyter/nwp-downscale/experiments/eval_wgan-gp_single_forecast_tp.json',\n",
    "          2: '/home/jupyter/nwp-downscale/experiments/eval_wgan-gp-smoothed_single_forecast_tp.json',\n",
    "          3: '/home/jupyter/nwp-downscale/experiments/eval_leingan_single_forecast_tp_input.json',\n",
    "          4: '/home/jupyter/nwp-downscale/experiments/eval_leingan_single_forecast_tp_with_consts_input.json',\n",
    "          5: '/home/jupyter/nwp-downscale/experiments/eval_leingan_ens10_tp_stacked_input.json',\n",
    "          6: '/home/jupyter/nwp-downscale/experiments/eval_leingan_ens10_tp_random_input.json',\n",
    "          7: '/home/jupyter/nwp-downscale/experiments/eval_leingan_ens10_tp_random_added_vars_TCW-T-CAPE-CIN.json',\n",
    "          8: '/home/jupyter/nwp-downscale/experiments/eval_leingan_single_forecast_tp_added_vars_TCW.json', \n",
    "          9: '/home/jupyter/nwp-downscale/experiments/eval_leingan_ens10_tp_random_input_ens_mean_L1_weighted_gen_loss.json', \n",
    "          10: '/home/jupyter/nwp-downscale/experiments/eval_leingan_pure_sr_on_ens10_tp_stacked.json', \n",
    "          11: '/home/jupyter/nwp-downscale/experiments/eval_leingan_single_forecast_tp_broadfield_channel_added_vars_TCW.json', \n",
    "         }\n",
    "\n",
    "json.dump(models, open('../experiments/model_eval_config_paths.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b466ebe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f6daba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f66028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa1199e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b209870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074f3c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44a5240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad89432",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MappingNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    <a id=\"mapping_network\"></a>\n",
    "    ## Mapping Network\n",
    "    ![Mapping Network](mapping_network.svg)\n",
    "    This is an MLP with 8 linear layers.\n",
    "    The mapping network maps the latent vector $z \\in \\mathcal{W}$\n",
    "    to an intermediate latent space $w \\in \\mathcal{W}$.\n",
    "    $\\mathcal{W}$ space will be disentangled from the image space\n",
    "    where the factors of variation become more linear.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, features: int, n_layers: int):\n",
    "        \"\"\"\n",
    "        * `features` is the number of features in $z$ and $w$\n",
    "        * `n_layers` is the number of layers in the mapping network.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Create the MLP\n",
    "        layers = []\n",
    "        for i in range(n_layers):\n",
    "            # [Equalized learning-rate linear layers](#equalized_linear)\n",
    "            layers.append(EqualizedLinear(features, features))\n",
    "            # Leaky Relu\n",
    "            layers.append(nn.LeakyReLU(negative_slope=0.2, inplace=True))\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, z: torch.Tensor):\n",
    "        # Normalize $z$\n",
    "        z = F.normalize(z, dim=1)\n",
    "        # Map $z$ to $w$\n",
    "        return self.net(z)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    <a id=\"generator\"></a>\n",
    "    ## StyleGAN2 Generator\n",
    "    ![Generator](style_gan2.svg)\n",
    "    *<small>$A$ denotes a linear layer.\n",
    "    $B$ denotes a broadcast and scaling operation (noise is a single channel).\n",
    "    [*toRGB*](#to_rgb) also has a style modulation which is not shown in the diagram to keep it simple.</small>*\n",
    "    The generator starts with a learned constant.\n",
    "    Then it has a series of blocks. The feature map resolution is doubled at each block\n",
    "    Each block outputs an RGB image and they are scaled up and summed to get the final RGB image.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, log_resolution: int, d_latent: int, n_features: int = 32, max_features: int = 512):\n",
    "        \"\"\"\n",
    "        * `log_resolution` is the $\\log_2$ of image resolution\n",
    "        * `d_latent` is the dimensionality of $w$\n",
    "        * `n_features` number of features in the convolution layer at the highest resolution (final block)\n",
    "        * `max_features` maximum number of features in any generator block\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Calculate the number of features for each block\n",
    "        #\n",
    "        # Something like `[512, 512, 256, 128, 64, 32]`\n",
    "        features = [min(max_features, n_features * (2 ** i)) for i in range(log_resolution - 2, -1, -1)]\n",
    "        # Number of generator blocks\n",
    "        self.n_blocks = len(features)\n",
    "\n",
    "        # Trainable $4 \\times 4$ constant\n",
    "        self.initial_constant = nn.Parameter(torch.randn((1, features[0], 4, 4)))\n",
    "\n",
    "        # First style block for $4 \\times 4$ resolution and layer to get RGB\n",
    "        self.style_block = StyleBlock(d_latent, features[0], features[0])\n",
    "        self.to_rgb = ToRGB(d_latent, features[0])\n",
    "\n",
    "        # Generator blocks\n",
    "        blocks = [GeneratorBlock(d_latent, features[i - 1], features[i]) for i in range(1, self.n_blocks)]\n",
    "        self.blocks = nn.ModuleList(blocks)\n",
    "\n",
    "        # $2 \\times$ up sampling layer. The feature space is up sampled\n",
    "        # at each block\n",
    "        self.up_sample = UpSample()\n",
    "\n",
    "    def forward(self, w: torch.Tensor, input_noise: List[Tuple[Optional[torch.Tensor], Optional[torch.Tensor]]]):\n",
    "        \"\"\"\n",
    "        * `w` is $w$. In order to mix-styles (use different $w$ for different layers), we provide a separate\n",
    "        $w$ for each [generator block](#generator_block). It has shape `[n_blocks, batch_size, d_latent]1.\n",
    "        * `input_noise` is the noise for each block.\n",
    "        It's a list of pairs of noise sensors because each block (except the initial) has two noise inputs\n",
    "        after each convolution layer (see the diagram).\n",
    "        \"\"\"\n",
    "\n",
    "        # Get batch size\n",
    "        batch_size = w.shape[1]\n",
    "\n",
    "        # Expand the learned constant to match batch size\n",
    "        x = self.initial_constant.expand(batch_size, -1, -1, -1)\n",
    "\n",
    "        # The first style block\n",
    "        x = self.style_block(x, w[0], input_noise[0][1])\n",
    "        # Get first rgb image\n",
    "        rgb = self.to_rgb(x, w[0])\n",
    "\n",
    "        # Evaluate rest of the blocks\n",
    "        for i in range(1, self.n_blocks):\n",
    "            # Up sample the feature map\n",
    "            x = self.up_sample(x)\n",
    "            # Run it through the [generator block](#generator_block)\n",
    "            x, rgb_new = self.blocks[i - 1](x, w[i], input_noise[i])\n",
    "            # Up sample the RGB image and add to the rgb from the block\n",
    "            rgb = self.up_sample(rgb) + rgb_new\n",
    "\n",
    "        # Return the final RGB image\n",
    "        return rgb\n",
    "\n",
    "\n",
    "class GeneratorBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    <a id=\"generator_block\"></a>\n",
    "    ### Generator Block\n",
    "    ![Generator block](generator_block.svg)\n",
    "    *<small>$A$ denotes a linear layer.\n",
    "    $B$ denotes a broadcast and scaling operation (noise is a single channel).\n",
    "    [*toRGB*](#to_rgb) also has a style modulation which is not shown in the diagram to keep it simple.</small>*\n",
    "    The generator block consists of two [style blocks](#style_block) ($3 \\times 3$ convolutions with style modulation)\n",
    "    and an RGB output.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_latent: int, in_features: int, out_features: int):\n",
    "        \"\"\"\n",
    "        * `d_latent` is the dimensionality of $w$\n",
    "        * `in_features` is the number of features in the input feature map\n",
    "        * `out_features` is the number of features in the output feature map\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # First [style block](#style_block) changes the feature map size to `out_features`\n",
    "        self.style_block1 = StyleBlock(d_latent, in_features, out_features)\n",
    "        # Second [style block](#style_block)\n",
    "        self.style_block2 = StyleBlock(d_latent, out_features, out_features)\n",
    "\n",
    "        # *toRGB* layer\n",
    "        self.to_rgb = ToRGB(d_latent, out_features)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, w: torch.Tensor, noise: Tuple[Optional[torch.Tensor], Optional[torch.Tensor]]):\n",
    "        \"\"\"\n",
    "        * `x` is the input feature map of shape `[batch_size, in_features, height, width]`\n",
    "        * `w` is $w$ with shape `[batch_size, d_latent]`\n",
    "        * `noise` is a tuple of two noise tensors of shape `[batch_size, 1, height, width]`\n",
    "        \"\"\"\n",
    "        # First style block with first noise tensor.\n",
    "        # The output is of shape `[batch_size, out_features, height, width]`\n",
    "        x = self.style_block1(x, w, noise[0])\n",
    "        # Second style block with second noise tensor.\n",
    "        # The output is of shape `[batch_size, out_features, height, width]`\n",
    "        x = self.style_block2(x, w, noise[1])\n",
    "\n",
    "        # Get RGB image\n",
    "        rgb = self.to_rgb(x, w)\n",
    "\n",
    "        # Return feature map and rgb image\n",
    "        return x, rgb\n",
    "\n",
    "\n",
    "class StyleBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    <a id=\"style_block\"></a>\n",
    "    ### Style Block\n",
    "    ![Style block](style_block.svg)\n",
    "    *<small>$A$ denotes a linear layer.\n",
    "    $B$ denotes a broadcast and scaling operation (noise is single channel).</small>*\n",
    "    Style block has a weight modulation convolution layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_latent: int, in_features: int, out_features: int):\n",
    "        \"\"\"\n",
    "        * `d_latent` is the dimensionality of $w$\n",
    "        * `in_features` is the number of features in the input feature map\n",
    "        * `out_features` is the number of features in the output feature map\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Get style vector from $w$ (denoted by $A$ in the diagram) with\n",
    "        # an [equalized learning-rate linear layer](#equalized_linear)\n",
    "        self.to_style = EqualizedLinear(d_latent, in_features, bias=1.0)\n",
    "        # Weight modulated convolution layer\n",
    "        self.conv = Conv2dWeightModulate(in_features, out_features, kernel_size=3)\n",
    "        # Noise scale\n",
    "        self.scale_noise = nn.Parameter(torch.zeros(1))\n",
    "        # Bias\n",
    "        self.bias = nn.Parameter(torch.zeros(out_features))\n",
    "\n",
    "        # Activation function\n",
    "        self.activation = nn.LeakyReLU(0.2, True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, w: torch.Tensor, noise: Optional[torch.Tensor]):\n",
    "        \"\"\"\n",
    "        * `x` is the input feature map of shape `[batch_size, in_features, height, width]`\n",
    "        * `w` is $w$ with shape `[batch_size, d_latent]`\n",
    "        * `noise` is a tensor of shape `[batch_size, 1, height, width]`\n",
    "        \"\"\"\n",
    "        # Get style vector $s$\n",
    "        s = self.to_style(w)\n",
    "        # Weight modulated convolution\n",
    "        x = self.conv(x, s)\n",
    "        # Scale and add noise\n",
    "        if noise is not None:\n",
    "            x = x + self.scale_noise[None, :, None, None] * noise\n",
    "        # Add bias and evaluate activation function\n",
    "        return self.activation(x + self.bias[None, :, None, None])\n",
    "\n",
    "\n",
    "class ToRGB(nn.Module):\n",
    "    \"\"\"\n",
    "    <a id=\"to_rgb\"></a>\n",
    "    ### To RGB\n",
    "    ![To RGB](to_rgb.svg)\n",
    "    *<small>$A$ denotes a linear layer.</small>*\n",
    "    Generates an RGB image from a feature map using $1 \\times 1$ convolution.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_latent: int, features: int):\n",
    "        \"\"\"\n",
    "        * `d_latent` is the dimensionality of $w$\n",
    "        * `features` is the number of features in the feature map\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Get style vector from $w$ (denoted by $A$ in the diagram) with\n",
    "        # an [equalized learning-rate linear layer](#equalized_linear)\n",
    "        self.to_style = EqualizedLinear(d_latent, features, bias=1.0)\n",
    "\n",
    "        # Weight modulated convolution layer without demodulation\n",
    "        self.conv = Conv2dWeightModulate(features, 3, kernel_size=1, demodulate=False)\n",
    "        # Bias\n",
    "        self.bias = nn.Parameter(torch.zeros(3))\n",
    "        # Activation function\n",
    "        self.activation = nn.LeakyReLU(0.2, True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, w: torch.Tensor):\n",
    "        \"\"\"\n",
    "        * `x` is the input feature map of shape `[batch_size, in_features, height, width]`\n",
    "        * `w` is $w$ with shape `[batch_size, d_latent]`\n",
    "        \"\"\"\n",
    "        # Get style vector $s$\n",
    "        style = self.to_style(w)\n",
    "        # Weight modulated convolution\n",
    "        x = self.conv(x, style)\n",
    "        # Add bias and evaluate activation function\n",
    "        return self.activation(x + self.bias[None, :, None, None])\n",
    "\n",
    "\n",
    "class Conv2dWeightModulate(nn.Module):\n",
    "    \"\"\"\n",
    "    ### Convolution with Weight Modulation and Demodulation\n",
    "    This layer scales the convolution weights by the style vector and demodulates by normalizing it.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features: int, out_features: int, kernel_size: int,\n",
    "                 demodulate: float = True, eps: float = 1e-8):\n",
    "        \"\"\"\n",
    "        * `in_features` is the number of features in the input feature map\n",
    "        * `out_features` is the number of features in the output feature map\n",
    "        * `kernel_size` is the size of the convolution kernel\n",
    "        * `demodulate` is flag whether to normalize weights by its standard deviation\n",
    "        * `eps` is the $\\epsilon$ for normalizing\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Number of output features\n",
    "        self.out_features = out_features\n",
    "        # Whether to normalize weights\n",
    "        self.demodulate = demodulate\n",
    "        # Padding size\n",
    "        self.padding = (kernel_size - 1) // 2\n",
    "\n",
    "        # [Weights parameter with equalized learning rate](#equalized_weight)\n",
    "        self.weight = EqualizedWeight([out_features, in_features, kernel_size, kernel_size])\n",
    "        # $\\epsilon$\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x: torch.Tensor, s: torch.Tensor):\n",
    "        \"\"\"\n",
    "        * `x` is the input feature map of shape `[batch_size, in_features, height, width]`\n",
    "        * `s` is style based scaling tensor of shape `[batch_size, in_features]`\n",
    "        \"\"\"\n",
    "\n",
    "        # Get batch size, height and width\n",
    "        b, _, h, w = x.shape\n",
    "\n",
    "        # Reshape the scales\n",
    "        s = s[:, None, :, None, None]\n",
    "        # Get [learning rate equalized weights](#equalized_weight)\n",
    "        weights = self.weight()[None, :, :, :, :]\n",
    "        # $$w`_{i,j,k} = s_i * w_{i,j,k}$$\n",
    "        # where $i$ is the input channel, $j$ is the output channel, and $k$ is the kernel index.\n",
    "        #\n",
    "        # The result has shape `[batch_size, out_features, in_features, kernel_size, kernel_size]`\n",
    "        weights = weights * s\n",
    "\n",
    "        # Demodulate\n",
    "        if self.demodulate:\n",
    "            # $$\\sigma_j = \\sqrt{\\sum_{i,k} (w'_{i, j, k})^2 + \\epsilon}$$\n",
    "            sigma_inv = torch.rsqrt((weights ** 2).sum(dim=(2, 3, 4), keepdim=True) + self.eps)\n",
    "            # $$w''_{i,j,k} = \\frac{w'_{i,j,k}}{\\sqrt{\\sum_{i,k} (w'_{i, j, k})^2 + \\epsilon}}$$\n",
    "            weights = weights * sigma_inv\n",
    "\n",
    "        # Reshape `x`\n",
    "        x = x.reshape(1, -1, h, w)\n",
    "\n",
    "        # Reshape weights\n",
    "        _, _, *ws = weights.shape\n",
    "        weights = weights.reshape(b * self.out_features, *ws)\n",
    "\n",
    "        # Use grouped convolution to efficiently calculate the convolution with sample wise kernel.\n",
    "        # i.e. we have a different kernel (weights) for each sample in the batch\n",
    "        x = F.conv2d(x, weights, padding=self.padding, groups=b)\n",
    "\n",
    "        # Reshape `x` to `[batch_size, out_features, height, width]` and return\n",
    "        return x.reshape(-1, self.out_features, h, w)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    <a id=\"discriminator\"></a>\n",
    "    ## StyleGAN 2 Discriminator\n",
    "    ![Discriminator](style_gan2_disc.svg)\n",
    "    Discriminator first transforms the image to a feature map of the same resolution and then\n",
    "    runs it through a series of blocks with residual connections.\n",
    "    The resolution is down-sampled by $2 \\times$ at each block while doubling the\n",
    "    number of features.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, log_resolution: int, n_features: int = 64, max_features: int = 512):\n",
    "        \"\"\"\n",
    "        * `log_resolution` is the $\\log_2$ of image resolution\n",
    "        * `n_features` number of features in the convolution layer at the highest resolution (first block)\n",
    "        * `max_features` maximum number of features in any generator block\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Layer to convert RGB image to a feature map with `n_features` number of features.\n",
    "        self.from_rgb = nn.Sequential(\n",
    "            EqualizedConv2d(3, n_features, 1),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "        )\n",
    "\n",
    "        # Calculate the number of features for each block.\n",
    "        #\n",
    "        # Something like `[64, 128, 256, 512, 512, 512]`.\n",
    "        features = [min(max_features, n_features * (2 ** i)) for i in range(log_resolution - 1)]\n",
    "        # Number of [discirminator blocks](#discriminator_block)\n",
    "        n_blocks = len(features) - 1\n",
    "        # Discriminator blocks\n",
    "        blocks = [DiscriminatorBlock(features[i], features[i + 1]) for i in range(n_blocks)]\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "\n",
    "        # [Mini-batch Standard Deviation](#mini_batch_std_dev)\n",
    "        self.std_dev = MiniBatchStdDev()\n",
    "        # Number of features after adding the standard deviations map\n",
    "        final_features = features[-1] + 1\n",
    "        # Final $3 \\times 3$ convolution layer\n",
    "        self.conv = EqualizedConv2d(final_features, final_features, 3)\n",
    "        # Final linear layer to get the classification\n",
    "        self.final = EqualizedLinear(2 * 2 * final_features, 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        * `x` is the input image of shape `[batch_size, 3, height, width]`\n",
    "        \"\"\"\n",
    "\n",
    "        # Try to normalize the image (this is totally optional, but sped up the early training a little)\n",
    "        x = x - 0.5\n",
    "        # Convert from RGB\n",
    "        x = self.from_rgb(x)\n",
    "        # Run through the [discriminator blocks](#discriminator_block)\n",
    "        x = self.blocks(x)\n",
    "\n",
    "        # Calculate and append [mini-batch standard deviation](#mini_batch_std_dev)\n",
    "        x = self.std_dev(x)\n",
    "        # $3 \\times 3$ convolution\n",
    "        x = self.conv(x)\n",
    "        # Flatten\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        # Return the classification score\n",
    "        return self.final(x)\n",
    "\n",
    "\n",
    "class DiscriminatorBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    <a id=\"discriminator_black\"></a>\n",
    "    ### Discriminator Block\n",
    "    ![Discriminator block](discriminator_block.svg)\n",
    "    Discriminator block consists of two $3 \\times 3$ convolutions with a residual connection.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features):\n",
    "        \"\"\"\n",
    "        * `in_features` is the number of features in the input feature map\n",
    "        * `out_features` is the number of features in the output feature map\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Down-sampling and $1 \\times 1$ convolution layer for the residual connection\n",
    "        self.residual = nn.Sequential(DownSample(),\n",
    "                                      EqualizedConv2d(in_features, out_features, kernel_size=1))\n",
    "\n",
    "        # Two $3 \\times 3$ convolutions\n",
    "        self.block = nn.Sequential(\n",
    "            EqualizedConv2d(in_features, in_features, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            EqualizedConv2d(in_features, out_features, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "        )\n",
    "\n",
    "        # Down-sampling layer\n",
    "        self.down_sample = DownSample()\n",
    "\n",
    "        # Scaling factor $\\frac{1}{\\sqrt 2}$ after adding the residual\n",
    "        self.scale = 1 / math.sqrt(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Get the residual connection\n",
    "        residual = self.residual(x)\n",
    "\n",
    "        # Convolutions\n",
    "        x = self.block(x)\n",
    "        # Down-sample\n",
    "        x = self.down_sample(x)\n",
    "\n",
    "        # Add the residual and scale\n",
    "        return (x + residual) * self.scale\n",
    "\n",
    "\n",
    "class MiniBatchStdDev(nn.Module):\n",
    "    \"\"\"\n",
    "    <a id=\"mini_batch_std_dev\"></a>\n",
    "    ### Mini-batch Standard Deviation\n",
    "    Mini-batch standard deviation calculates the standard deviation\n",
    "    across a mini-batch (or a subgroups within the mini-batch)\n",
    "    for each feature in the feature map. Then it takes the mean of all\n",
    "    the standard deviations and appends it to the feature map as one extra feature.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, group_size: int = 4):\n",
    "        \"\"\"\n",
    "        * `group_size` is the number of samples to calculate standard deviation across.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.group_size = group_size\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        * `x` is the feature map\n",
    "        \"\"\"\n",
    "        # Check if the batch size is divisible by the group size\n",
    "        assert x.shape[0] % self.group_size == 0\n",
    "        # Split the samples into groups of `group_size`, we flatten the feature map to a single dimension\n",
    "        # since we want to calculate the standard deviation for each feature.\n",
    "        grouped = x.view(self.group_size, -1)\n",
    "        # Calculate the standard deviation for each feature among `group_size` samples\n",
    "        # $$\\mu_{i} = \\frac{1}{N} \\sum_g x_{g,i} \\\\\n",
    "        #   \\sigma_{i} = \\sqrt{\\frac{1}{N} \\sum_g (x_{g,i} - \\mu_i)^2  + \\epsilon}$$\n",
    "        std = torch.sqrt(grouped.var(dim=0) + 1e-8)\n",
    "        # Get the mean standard deviation\n",
    "        std = std.mean().view(1, 1, 1, 1)\n",
    "        # Expand the standard deviation to append to the feature map\n",
    "        b, _, h, w = x.shape\n",
    "        std = std.expand(b, -1, h, w)\n",
    "        # Append (concatenate) the standard deviations to the feature map\n",
    "        return torch.cat([x, std], dim=1)\n",
    "\n",
    "\n",
    "class DownSample(nn.Module):\n",
    "    \"\"\"\n",
    "    <a id=\"down_sample\"></a>\n",
    "    ### Down-sample\n",
    "    The down-sample operation [smoothens](#smooth) each feature channel and\n",
    "     scale $2 \\times$ using bilinear interpolation.\n",
    "    This is based on the paper\n",
    "     [Making Convolutional Networks Shift-Invariant Again](https://papers.labml.ai/paper/1904.11486).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Smoothing layer\n",
    "        self.smooth = Smooth()\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # Smoothing or blurring\n",
    "        x = self.smooth(x)\n",
    "        # Scaled down\n",
    "        return F.interpolate(x, (x.shape[2] // 2, x.shape[3] // 2), mode='bilinear', align_corners=False)\n",
    "\n",
    "\n",
    "class UpSample(nn.Module):\n",
    "    \"\"\"\n",
    "    <a id=\"up_sample\"></a>\n",
    "    ### Up-sample\n",
    "    The up-sample operation scales the image up by $2 \\times$ and [smoothens](#smooth) each feature channel.\n",
    "    This is based on the paper\n",
    "     [Making Convolutional Networks Shift-Invariant Again](https://papers.labml.ai/paper/1904.11486).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Up-sampling layer\n",
    "        self.up_sample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        # Smoothing layer\n",
    "        self.smooth = Smooth()\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # Up-sample and smoothen\n",
    "        return self.smooth(self.up_sample(x))\n",
    "\n",
    "\n",
    "class Smooth(nn.Module):\n",
    "    \"\"\"\n",
    "    <a id=\"smooth\"></a>\n",
    "    ### Smoothing Layer\n",
    "    This layer blurs each channel\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Blurring kernel\n",
    "        kernel = [[1, 2, 1],\n",
    "                  [2, 4, 2],\n",
    "                  [1, 2, 1]]\n",
    "        # Convert the kernel to a PyTorch tensor\n",
    "        kernel = torch.tensor([[kernel]], dtype=torch.float)\n",
    "        # Normalize the kernel\n",
    "        kernel /= kernel.sum()\n",
    "        # Save kernel as a fixed parameter (no gradient updates)\n",
    "        self.kernel = nn.Parameter(kernel, requires_grad=False)\n",
    "        # Padding layer\n",
    "        self.pad = nn.ReplicationPad2d(1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # Get shape of the input feature map\n",
    "        b, c, h, w = x.shape\n",
    "        # Reshape for smoothening\n",
    "        x = x.view(-1, 1, h, w)\n",
    "\n",
    "        # Add padding\n",
    "        x = self.pad(x)\n",
    "\n",
    "        # Smoothen (blur) with the kernel\n",
    "        x = F.conv2d(x, self.kernel)\n",
    "\n",
    "        # Reshape and return\n",
    "        return x.view(b, c, h, w)\n",
    "\n",
    "\n",
    "class EqualizedLinear(nn.Module):\n",
    "    \"\"\"\n",
    "    <a id=\"equalized_linear\"></a>\n",
    "    ## Learning-rate Equalized Linear Layer\n",
    "    This uses [learning-rate equalized weights]($equalized_weights) for a linear layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features: int, out_features: int, bias: float = 0.):\n",
    "        \"\"\"\n",
    "        * `in_features` is the number of features in the input feature map\n",
    "        * `out_features` is the number of features in the output feature map\n",
    "        * `bias` is the bias initialization constant\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        # [Learning-rate equalized weights]($equalized_weights)\n",
    "        self.weight = EqualizedWeight([out_features, in_features])\n",
    "        # Bias\n",
    "        self.bias = nn.Parameter(torch.ones(out_features) * bias)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # Linear transformation\n",
    "        return F.linear(x, self.weight(), bias=self.bias)\n",
    "\n",
    "\n",
    "class EqualizedConv2d(nn.Module):\n",
    "    \"\"\"\n",
    "    <a id=\"equalized_conv2d\"></a>\n",
    "    ## Learning-rate Equalized 2D Convolution Layer\n",
    "    This uses [learning-rate equalized weights]($equalized_weights) for a convolution layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features: int, out_features: int,\n",
    "                 kernel_size: int, padding: int = 0):\n",
    "        \"\"\"\n",
    "        * `in_features` is the number of features in the input feature map\n",
    "        * `out_features` is the number of features in the output feature map\n",
    "        * `kernel_size` is the size of the convolution kernel\n",
    "        * `padding` is the padding to be added on both sides of each size dimension\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Padding size\n",
    "        self.padding = padding\n",
    "        # [Learning-rate equalized weights]($equalized_weights)\n",
    "        self.weight = EqualizedWeight([out_features, in_features, kernel_size, kernel_size])\n",
    "        # Bias\n",
    "        self.bias = nn.Parameter(torch.ones(out_features))\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # Convolution\n",
    "        return F.conv2d(x, self.weight(), bias=self.bias, padding=self.padding)\n",
    "\n",
    "\n",
    "class EqualizedWeight(nn.Module):\n",
    "    \"\"\"\n",
    "    <a id=\"equalized_weight\"></a>\n",
    "    ## Learning-rate Equalized Weights Parameter\n",
    "    This is based on equalized learning rate introduced in the Progressive GAN paper.\n",
    "    Instead of initializing weights at $\\mathcal{N}(0,c)$ they initialize weights\n",
    "    to $\\mathcal{N}(0, 1)$ and then multiply them by $c$ when using it.\n",
    "    $$w_i = c \\hat{w}_i$$\n",
    "    The gradients on stored parameters $\\hat{w}$ get multiplied by $c$ but this doesn't have\n",
    "    an affect since optimizers such as Adam normalize them by a running mean of the squared gradients.\n",
    "    The optimizer updates on $\\hat{w}$ are proportionate to the learning rate $\\lambda$.\n",
    "    But the effective weights $w$ get updated proportionately to $c \\lambda$.\n",
    "    Without equalized learning rate, the effective weights will get updated proportionately to just $\\lambda$.\n",
    "    So we are effectively scaling the learning rate by $c$ for these weight parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, shape: List[int]):\n",
    "        \"\"\"\n",
    "        * `shape` is the shape of the weight parameter\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # He initialization constant\n",
    "        self.c = 1 / math.sqrt(np.prod(shape[1:]))\n",
    "        # Initialize the weights with $\\mathcal{N}(0, 1)$\n",
    "        self.weight = nn.Parameter(torch.randn(shape))\n",
    "        # Weight multiplication coefficient\n",
    "\n",
    "    def forward(self):\n",
    "        # Multiply the weights by $c$ and return\n",
    "        return self.weight * self.c\n",
    "\n",
    "\n",
    "class GradientPenalty(nn.Module):\n",
    "    \"\"\"\n",
    "    <a id=\"gradient_penalty\"></a>\n",
    "    ## Gradient Penalty\n",
    "    This is the $R_1$ regularization penality from the paper\n",
    "    [Which Training Methods for GANs do actually Converge?](https://papers.labml.ai/paper/1801.04406).\n",
    "    $$R_1(\\psi) = \\frac{\\gamma}{2} \\mathbb{E}_{p_\\mathcal{D}(x)}\n",
    "    \\Big[\\Vert \\nabla_x D_\\psi(x)^2 \\Vert\\Big]$$\n",
    "    That is we try to reduce the L2 norm of gradients of the discriminator with\n",
    "    respect to images, for real images ($P_\\mathcal{D}$).\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x: torch.Tensor, d: torch.Tensor):\n",
    "        \"\"\"\n",
    "        * `x` is $x \\sim \\mathcal{D}$\n",
    "        * `d` is $D(x)$\n",
    "        \"\"\"\n",
    "\n",
    "        # Get batch size\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        # Calculate gradients of $D(x)$ with respect to $x$.\n",
    "        # `grad_outputs` is set to $1$ since we want the gradients of $D(x)$,\n",
    "        # and we need to create and retain graph since we have to compute gradients\n",
    "        # with respect to weight on this loss.\n",
    "        gradients, *_ = torch.autograd.grad(outputs=d,\n",
    "                                            inputs=x,\n",
    "                                            grad_outputs=d.new_ones(d.shape),\n",
    "                                            create_graph=True)\n",
    "\n",
    "        # Reshape gradients to calculate the norm\n",
    "        gradients = gradients.reshape(batch_size, -1)\n",
    "        # Calculate the norm $\\Vert \\nabla_{x} D(x)^2 \\Vert$\n",
    "        norm = gradients.norm(2, dim=-1)\n",
    "        # Return the loss $\\Vert \\nabla_x D_\\psi(x)^2 \\Vert$\n",
    "        return torch.mean(norm ** 2)\n",
    "\n",
    "\n",
    "class PathLengthPenalty(nn.Module):\n",
    "    \"\"\"\n",
    "    <a id=\"path_length_penalty\"></a>\n",
    "    ## Path Length Penalty\n",
    "    This regularization encourages a fixed-size step in $w$ to result in a fixed-magnitude\n",
    "    change in the image.\n",
    "    $$\\mathbb{E}_{w \\sim f(z), y \\sim \\mathcal{N}(0, \\mathbf{I})}\n",
    "      \\Big(\\Vert \\mathbf{J}^\\top_{w} y \\Vert_2 - a \\Big)^2$$\n",
    "    where $\\mathbf{J}_w$ is the Jacobian\n",
    "    $\\mathbf{J}_w = \\frac{\\partial g}{\\partial w}$,\n",
    "    $w$ are sampled from $w \\in \\mathcal{W}$ from the mapping network, and\n",
    "    $y$ are images with noise $\\mathcal{N}(0, \\mathbf{I})$.\n",
    "    $a$ is the exponential moving average of $\\Vert \\mathbf{J}^\\top_{w} y \\Vert_2$\n",
    "    as the training progresses.\n",
    "    $\\mathbf{J}^\\top_{w} y$ is calculated without explicitly calculating the Jacobian using\n",
    "    $$\\mathbf{J}^\\top_{w} y = \\nabla_w \\big(g(w) \\cdot y \\big)$$\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, beta: float):\n",
    "        \"\"\"\n",
    "        * `beta` is the constant $\\beta$ used to calculate the exponential moving average $a$\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # $\\beta$\n",
    "        self.beta = beta\n",
    "        # Number of steps calculated $N$\n",
    "        self.steps = nn.Parameter(torch.tensor(0.), requires_grad=False)\n",
    "        # Exponential sum of $\\mathbf{J}^\\top_{w} y$\n",
    "        # $$\\sum^N_{i=1} \\beta^{(N - i)}[\\mathbf{J}^\\top_{w} y]_i$$\n",
    "        # where $[\\mathbf{J}^\\top_{w} y]_i$ is the value of it at $i$-th step of training\n",
    "        self.exp_sum_a = nn.Parameter(torch.tensor(0.), requires_grad=False)\n",
    "\n",
    "    def forward(self, w: torch.Tensor, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        * `w` is the batch of $w$ of shape `[batch_size, d_latent]`\n",
    "        * `x` are the generated images of shape `[batch_size, 3, height, width]`\n",
    "        \"\"\"\n",
    "\n",
    "        # Get the device\n",
    "        device = x.device\n",
    "        # Get number of pixels\n",
    "        image_size = x.shape[2] * x.shape[3]\n",
    "        # Calculate $y \\in \\mathcal{N}(0, \\mathbf{I})$\n",
    "        y = torch.randn(x.shape, device=device)\n",
    "        # Calculate $\\big(g(w) \\cdot y \\big)$ and normalize by the square root of image size.\n",
    "        # This is scaling is not mentioned in the paper but was present in\n",
    "        # [their implementation](https://github.com/NVlabs/stylegan2/blob/master/training/loss.py#L167).\n",
    "        output = (x * y).sum() / math.sqrt(image_size)\n",
    "\n",
    "        # Calculate gradients to get $\\mathbf{J}^\\top_{w} y$\n",
    "        gradients, *_ = torch.autograd.grad(outputs=output,\n",
    "                                            inputs=w,\n",
    "                                            grad_outputs=torch.ones(output.shape, device=device),\n",
    "                                            create_graph=True)\n",
    "\n",
    "        # Calculate L2-norm of $\\mathbf{J}^\\top_{w} y$\n",
    "        norm = (gradients ** 2).sum(dim=2).mean(dim=1).sqrt()\n",
    "\n",
    "        # Regularize after first step\n",
    "        if self.steps > 0:\n",
    "            # Calculate $a$\n",
    "            # $$\\frac{1}{1 - \\beta^N} \\sum^N_{i=1} \\beta^{(N - i)}[\\mathbf{J}^\\top_{w} y]_i$$\n",
    "            a = self.exp_sum_a / (1 - self.beta ** self.steps)\n",
    "            # Calculate the penalty\n",
    "            # $$\\mathbb{E}_{w \\sim f(z), y \\sim \\mathcal{N}(0, \\mathbf{I})}\n",
    "            # \\Big(\\Vert \\mathbf{J}^\\top_{w} y \\Vert_2 - a \\Big)^2$$\n",
    "            loss = torch.mean((norm - a) ** 2)\n",
    "        else:\n",
    "            # Return a dummy loss if we can't calculate $a$\n",
    "            loss = norm.new_tensor(0)\n",
    "\n",
    "        # Calculate the mean of $\\Vert \\mathbf{J}^\\top_{w} y \\Vert_2$\n",
    "        mean = norm.mean().detach()\n",
    "        # Update exponential sum\n",
    "        self.exp_sum_a.mul_(self.beta).add_(mean, alpha=1 - self.beta)\n",
    "        # Increment $N$\n",
    "        self.steps.add_(1.)\n",
    "\n",
    "        # Return the penalty\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    ## Dataset\n",
    "    This loads the training dataset and resize it to the give image size.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path: str, image_size: int):\n",
    "        \"\"\"\n",
    "        * `path` path to the folder containing the images\n",
    "        * `image_size` size of the image\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Get the paths of all `jpg` files\n",
    "        self.paths = [p for p in Path(path).glob(f'**/*.jpg')]\n",
    "\n",
    "        # Transformation\n",
    "        self.transform = torchvision.transforms.Compose([\n",
    "            # Resize the image\n",
    "            torchvision.transforms.Resize(image_size),\n",
    "            # Convert to PyTorch tensor\n",
    "            torchvision.transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of images\"\"\"\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get the the `index`-th image\"\"\"\n",
    "        path = self.paths[index]\n",
    "        img = Image.open(path)\n",
    "        return self.transform(img)\n",
    "    \n",
    "    \n",
    "    \n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    ## Dataset\n",
    "    This loads the training dataset and resize it to the give image size.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path: str, image_size: int):\n",
    "        \"\"\"\n",
    "        * `path` path to the folder containing the images\n",
    "        * `image_size` size of the image\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Get the paths of all `jpg` files\n",
    "        self.paths = [p for p in Path(path).glob(f'**/*.jpg')]\n",
    "        \n",
    "#         print(list(Path(path).glob(f'**/*.jpg')))\n",
    "        \n",
    "        # Transformation\n",
    "        self.transform = torchvision.transforms.Compose([\n",
    "            # Resize the image\n",
    "            torchvision.transforms.Resize(image_size),\n",
    "            # Convert to PyTorch tensor\n",
    "            torchvision.transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of images\"\"\"\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get the the `index`-th image\"\"\"\n",
    "        path = self.paths[index]\n",
    "        img = Image.open(path)\n",
    "        return self.transform(img), self.transform(img)\n",
    "    \n",
    "    \n",
    "from typing import Any, TypeVar, Iterator, Iterable, Generic\n",
    "\n",
    "class Module(torch.nn.Module):\n",
    "    r\"\"\"\n",
    "    Wraps ``torch.nn.Module`` to overload ``__call__`` instead of\n",
    "    ``forward`` for better type checking.\n",
    "    \n",
    "    `PyTorch Github issue for clarification <https://github.com/pytorch/pytorch/issues/44605>`_\n",
    "    \"\"\"\n",
    "\n",
    "    def _forward_unimplemented(self, *input: Any) -> None:\n",
    "        # To stop PyTorch from giving abstract methods warning\n",
    "        pass\n",
    "\n",
    "    def __init_subclass__(cls, **kwargs):\n",
    "        if cls.__dict__.get('__call__', None) is None:\n",
    "            return\n",
    "\n",
    "        setattr(cls, 'forward', cls.__dict__['__call__'])\n",
    "        delattr(cls, '__call__')\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        params = self.parameters()\n",
    "        try:\n",
    "            sample_param = next(params)\n",
    "            return sample_param.device\n",
    "        except StopIteration:\n",
    "            raise RuntimeError(f\"Unable to determine\"\n",
    "                               f\" device of {self.__class__.__name__}\") from None\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "class DiscriminatorLoss(Module):\n",
    "    \"\"\"\n",
    "    ## Discriminator Loss\n",
    "    We want to find $w$ to maximize\n",
    "    $$\\mathbb{E}_{x \\sim \\mathbb{P}_r} [f_w(x)]- \\mathbb{E}_{z \\sim p(z)} [f_w(g_\\theta(z))]$$,\n",
    "    so we minimize,\n",
    "    $$-\\frac{1}{m} \\sum_{i=1}^m f_w \\big(x^{(i)} \\big) +\n",
    "     \\frac{1}{m} \\sum_{i=1}^m f_w \\big( g_\\theta(z^{(i)}) \\big)$$\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, f_real: torch.Tensor, f_fake: torch.Tensor):\n",
    "        \"\"\"\n",
    "        * `f_real` is $f_w(x)$\n",
    "        * `f_fake` is $f_w(g_\\theta(z))$\n",
    "        This returns the a tuple with losses for $f_w(x)$ and $f_w(g_\\theta(z))$,\n",
    "        which are later added.\n",
    "        They are kept separate for logging.\n",
    "        \"\"\"\n",
    "\n",
    "        # We use ReLUs to clip the loss to keep $f \\in [-1, +1]$ range.\n",
    "        return F.relu(1 - f_real).mean(), F.relu(1 + f_fake).mean()\n",
    "\n",
    "\n",
    "class GeneratorLoss(Module):\n",
    "    \"\"\"\n",
    "    ## Generator Loss\n",
    "    We want to find $\\theta$ to minimize\n",
    "    $$\\mathbb{E}_{x \\sim \\mathbb{P}_r} [f_w(x)]- \\mathbb{E}_{z \\sim p(z)} [f_w(g_\\theta(z))]$$\n",
    "    The first component is independent of $\\theta$,\n",
    "    so we minimize,\n",
    "    $$-\\frac{1}{m} \\sum_{i=1}^m f_w \\big( g_\\theta(z^{(i)}) \\big)$$\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, f_fake: torch.Tensor):\n",
    "        \"\"\"\n",
    "        * `f_fake` is $f_w(g_\\theta(z))$\n",
    "        \"\"\"\n",
    "        return -f_fake.mean()\n",
    "\n",
    "    \n",
    "class StyleGan2(LightningModule):\n",
    "    def __init__(self): # fill in\n",
    "        super().__init__()\n",
    "        self.image_size = 128\n",
    "        self.d_latent = 512\n",
    "        log_resolution = int(math.log2(self.image_size))\n",
    "        self.learning_rate = 1e-3\n",
    "        self.mapping_network_learning_rate = 1e-5\n",
    "        \n",
    "        self.style_mixing_prob = 0.9\n",
    "        \n",
    "        # Create discriminator and generator\n",
    "        self.discriminator = Discriminator(log_resolution)\n",
    "        self.generator = Generator(log_resolution, self.d_latent)\n",
    "        # Get number of generator blocks for creating style and noise inputs\n",
    "        self.n_gen_blocks = self.generator.n_blocks\n",
    "        # Create mapping network\n",
    "        self.mapping_network_layers = 8\n",
    "        self.mapping_network = MappingNetwork(self.d_latent, self.mapping_network_layers)\n",
    " \n",
    "        # Create path length penalty loss\n",
    "        self.discriminator_loss = DiscriminatorLoss()\n",
    "        self.generator_loss = GeneratorLoss()\n",
    "        \n",
    "        self.lazy_gradient_penalty_interval = 4\n",
    "        self.batch_size = 32\n",
    "        self.gradient_penalty = GradientPenalty()\n",
    "        self.gradient_penalty_coefficient = 10.0\n",
    "        self.path_length_penalty = PathLengthPenalty(0.99)\n",
    "        self.lazy_path_penalty_interval = 32\n",
    "        self.lazy_path_penalty_after = 5000\n",
    "        \n",
    "        self.automatic_optimization = False\n",
    "#         self.gradient_accumulate_steps = 1\n",
    "        \n",
    "#         self.save_hyperparameters()\n",
    "        \n",
    "    def get_w(self, batch_size: int):\n",
    "        \"\"\"\n",
    "        ### Sample $w$\n",
    "        This samples $z$ randomly and get $w$ from the mapping network.\n",
    "        We also apply style mixing sometimes where we generate two latent variables\n",
    "        $z_1$ and $z_2$ and get corresponding $w_1$ and $w_2$.\n",
    "        Then we randomly sample a cross-over point and apply $w_1$ to\n",
    "        the generator blocks before the cross-over point and\n",
    "        $w_2$ to the blocks after.\n",
    "        \"\"\"\n",
    "\n",
    "        # Mix styles\n",
    "        if torch.rand(()).item() < self.style_mixing_prob:\n",
    "            # Random cross-over point\n",
    "            cross_over_point = int(torch.rand(()).item() * self.n_gen_blocks)\n",
    "            # Sample $z_1$ and $z_2$\n",
    "            z2 = torch.randn(batch_size, self.d_latent).to(self.device)\n",
    "            z1 = torch.randn(batch_size, self.d_latent).to(self.device)\n",
    "            # Get $w_1$ and $w_2$\n",
    "            w1 = self.mapping_network(z1)\n",
    "            w2 = self.mapping_network(z2)\n",
    "            # Expand $w_1$ and $w_2$ for the generator blocks and concatenate\n",
    "            w1 = w1[None, :, :].expand(cross_over_point, -1, -1)\n",
    "            w2 = w2[None, :, :].expand(self.n_gen_blocks - cross_over_point, -1, -1)\n",
    "            return torch.cat((w1, w2), dim=0)\n",
    "        # Without mixing\n",
    "        else:\n",
    "            # Sample $z$ and $z$\n",
    "            z = torch.randn(batch_size, self.d_latent).to(self.device)\n",
    "            # Get $w$ and $w$\n",
    "            w = self.mapping_network(z)\n",
    "            # Expand $w$ for the generator blocks\n",
    "            return w[None, :, :].expand(self.n_gen_blocks, -1, -1)\n",
    "\n",
    "    def get_noise(self, batch_size: int):\n",
    "        \"\"\"\n",
    "        ### Generate noise\n",
    "        This generates noise for each [generator block](index.html#generator_block)\n",
    "        \"\"\"\n",
    "        # List to store noise\n",
    "        noise = []\n",
    "        # Noise resolution starts from $4$\n",
    "        resolution = 4\n",
    "\n",
    "        # Generate noise for each generator block\n",
    "        for i in range(self.n_gen_blocks):\n",
    "            # The first block has only one $3 \\times 3$ convolution\n",
    "            if i == 0:\n",
    "                n1 = None\n",
    "            # Generate noise to add after the first convolution layer\n",
    "            else:\n",
    "                n1 = torch.randn(batch_size, 1, resolution, resolution, device=self.device)\n",
    "            # Generate noise to add after the second convolution layer\n",
    "            n2 = torch.randn(batch_size, 1, resolution, resolution, device=self.device)\n",
    "\n",
    "            # Add noise tensors to the list\n",
    "            noise.append((n1, n2))\n",
    "\n",
    "            # Next block has $2 \\times$ resolution\n",
    "            resolution *= 2\n",
    "\n",
    "        # Return noise tensors\n",
    "        return noise\n",
    "\n",
    "    def generate_images(self, batch_size: int):\n",
    "        \"\"\"\n",
    "        ### Generate images\n",
    "        This generate images using the generator\n",
    "        \"\"\"\n",
    "\n",
    "        # Get $w$\n",
    "        w = self.get_w(batch_size)\n",
    "        # Get noise\n",
    "        noise = self.get_noise(batch_size)\n",
    "\n",
    "        # Generate images\n",
    "        images = self.generator(w, noise)\n",
    "\n",
    "        # Return images and $w$\n",
    "        return images, w\n",
    "\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        condition, real_images = batch[0], batch[1]\n",
    "        \n",
    "        discriminator_optimizer, generator_optimizer, mapping_network_optimizer = self.optimizers()\n",
    "        \n",
    "        # Sample images from generator\n",
    "        generated_images, _ = self.generate_images(self.batch_size)\n",
    "        # Discriminator classification for generated images\n",
    "        fake_output = self.discriminator(generated_images.detach())\n",
    "\n",
    "        # We need to calculate gradients w.r.t. real images for gradient penalty\n",
    "        if (self.global_step + 1) % self.lazy_gradient_penalty_interval == 0:\n",
    "            real_images.requires_grad_()\n",
    "        # Discriminator classification for real images\n",
    "        real_output = self.discriminator(real_images)\n",
    "\n",
    "        # Get discriminator loss\n",
    "        real_loss, fake_loss = self.discriminator_loss(real_output, fake_output)\n",
    "        disc_loss = real_loss + fake_loss\n",
    "\n",
    "        # Add gradient penalty\n",
    "        if (self.global_step + 1) % self.lazy_gradient_penalty_interval == 0:\n",
    "            # Calculate and log gradient penalty\n",
    "            gp = self.gradient_penalty(real_images, real_output)\n",
    "            # Multiply by coefficient and add gradient penalty\n",
    "            print(\"gp:\", gp)\n",
    "            disc_loss = disc_loss + 0.5 * self.gradient_penalty_coefficient * gp * self.lazy_gradient_penalty_interval\n",
    "\n",
    "        # Compute gradients\n",
    "        discriminator_optimizer.zero_grad()\n",
    "        self.manual_backward(disc_loss)\n",
    "        \n",
    "        grads = [par.grad for par in self.discriminator.parameters() if (par.grad is not None)]\n",
    "        max_grad = max([torch.max(g) for g in grads])\n",
    "        print(\"num params:\", len(list(self.discriminator.parameters())))\n",
    "        print(\"number params with grad:\", len(grads))\n",
    "        \n",
    "        grad_param_shapes = [par.grad.shape for par in self.discriminator.parameters() if (par.grad is not None)]\n",
    "        print(\"grad param shapes:\", grad_param_shapes)\n",
    "        print(\"max_grad:\", max_grad)\n",
    "                             \n",
    "        # Clip gradients for stabilization\n",
    "        torch.nn.utils.clip_grad_norm_(self.discriminator.parameters(), max_norm=1.0)\n",
    "        # Take optimizer step\n",
    "        discriminator_optimizer.step()\n",
    "    \n",
    "        # Sample images from generator\n",
    "        generated_images, w = self.generate_images(self.batch_size)\n",
    "        # Discriminator classification for generated images\n",
    "        fake_output = self.discriminator(generated_images)\n",
    "\n",
    "        # Get generator loss\n",
    "        gen_loss = self.generator_loss(fake_output)\n",
    "\n",
    "        # Add path length penalty\n",
    "        if self.global_step > self.lazy_path_penalty_after and (self.global_step + 1) % self.lazy_path_penalty_interval == 0:\n",
    "            # Calculate path length penalty\n",
    "            plp = self.path_length_penalty(w, generated_images)\n",
    "            # Ignore if `nan`\n",
    "            if not torch.isnan(plp):\n",
    "                gen_loss = gen_loss + plp\n",
    "\n",
    "        # Reset gradients\n",
    "        generator_optimizer.zero_grad()\n",
    "        mapping_network_optimizer.zero_grad()\n",
    "        \n",
    "        # Calculate gradients\n",
    "        self.manual_backward(gen_loss)\n",
    "        \n",
    "        # Clip gradients for stabilization\n",
    "        torch.nn.utils.clip_grad_norm_(self.generator.parameters(), max_norm=1.0)\n",
    "        torch.nn.utils.clip_grad_norm_(self.mapping_network.parameters(), max_norm=1.0)\n",
    "\n",
    "        # Take optimizer step\n",
    "        generator_optimizer.step()\n",
    "        mapping_network_optimizer.step()\n",
    "        \n",
    "        # Log loss\n",
    "        \n",
    "        self.log('discriminator_loss', disc_loss, on_epoch=True, on_step=True, prog_bar=True, logger=True)\n",
    "        self.log('generator_loss', gen_loss, on_epoch=True, on_step=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        generator_optimizer = optim.Adam(self.generator.parameters(), lr=self.learning_rate, betas=(0, 0.99))\n",
    "        discriminator_optimizer = optim.Adam(self.discriminator.parameters(), lr=self.learning_rate, betas=(0, 0.99))\n",
    "        mapping_network_optimizer = optim.Adam(self.mapping_network.parameters(), lr=self.mapping_network_learning_rate, betas=(0, 0.99))\n",
    "            \n",
    "        return discriminator_optimizer, generator_optimizer, mapping_network_optimizer\n",
    "    \n",
    "    def forward(self):\n",
    "        return self.gen(x,w,noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a9f160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d66da9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread('/home/jupyter/data/stylegan2/img_align_celeba/000002.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee69c5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f034e571fd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img[:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e784cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218, 178, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e2121f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"
  },
  "kernelspec": {
   "display_name": "Python [conda env:ilan]",
   "language": "python",
   "name": "conda-env-ilan-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
